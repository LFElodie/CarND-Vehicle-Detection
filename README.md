## README

**Vehicle Detection Project**

The goals / steps of this project are the following:

- Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier
- Apply a color transform and append binned color features, as well as histograms of color, to HOG feature vector. 
- Normalize features and randomize a selection for training and testing.
- Implement a sliding-window technique and use trained classifier to search for vehicles in images.
- Run pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.
- Estimate a bounding box for vehicles detected.

### Histogram of Oriented Gradients (HOG)

#### 1. Extraction of HOG features, histogram and spatial features from the training images.

The code for this step is contained in the first code cell of the ` visualization.ipynb`.

I started by reading in all the `vehicle` and `non-vehicle` images.  Here is an example of the `vehicle` and `non-vehicle` classes:

![](http://p37mg8cnp.bkt.clouddn.com/github/md/cars_notcars.png)

I then explored different color spaces and different `skimage.hog()` parameters (`orientations`, `pixels_per_cell`, and `cells_per_block`).  I grabbed random images from each of the two classes and displayed them to get a feel for what the `skimage.hog()` output looks like.

Here is an example using the `YCrCb` color space and HOG parameters of `orientations=9`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`:


![](http://p37mg8cnp.bkt.clouddn.com/github/md/hog_show.png)

![](http://p37mg8cnp.bkt.clouddn.com/github/md/histogram.png)

![](http://p37mg8cnp.bkt.clouddn.com/github/md/spatial.png)

#### 2. Parameters for HOG features, histogram and spatial features.

I tried various combinations of parameters and trained a linear SVM.

I finally chose HLS space Â `pixels_per_cell=8`, `orient=9`,`cells_per_block=2`. Using values larger than those did not improve results and only increased the feature vector. That is why these values were chosen.

#### 3. Training a classifier using selected HOG features and color features.

I trained a linear SVM with the default classifier parameters and using HOG features with parameters describe above, spatial features with size 32 and histogram features with 32 bins.





### Sliding Window Search

#### 1. What scales to search and how much to overlap windows.

I decided to search random window positions at random scales all over the image and came up with this (ok just kidding I didn't actually ;):

![alt text][image3]

#### 2. Show some examples of test images to demonstrate how your pipeline is working.  What did you do to optimize the performance of your classifier?

Ultimately I searched on two scales using YCrCb 3-channel HOG features plus spatially binned color and histograms of color in the feature vector, which provided a nice result.  Here are some example images

![]()

### Video Implementation

#### 1. Here's a [link to my video result](./project_video.mp4)

#### 2. Some kind of filter for false positives and some method for combining overlapping bounding boxes.

I recorded the positions of positive detections in each frame of the video.  From the positive detections I created a heatmap and then thresholded that map to identify vehicle positions.  I then used `scipy.ndimage.measurements.label()` to identify individual blobs in the heatmap.  I then assumed each blob corresponded to a vehicle.  I constructed bounding boxes to cover the area of each blob detected.  

Here's an example result showing the heatmap from a series of frames of video, the result of `scipy.ndimage.measurements.label()` and the bounding boxes then overlaid on the last frame of video:

### Here are six frames and their corresponding heatmaps:

![](http://p37mg8cnp.bkt.clouddn.com/github/md/heatmap.png)

### Here is the output of `scipy.ndimage.measurements.label()` on the integrated heatmap from all six frames:
![](http://p37mg8cnp.bkt.clouddn.com/github/md/intheatmap.png)

### Here the resulting bounding boxes are drawn onto the last frame in the series:
![alt text][image7]



---

### Discussion

#### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?

Here I'll talk about the approach I took, what techniques I used, what worked and why, where the pipeline might fail and how I might improve it if I were going to pursue this project further.  

